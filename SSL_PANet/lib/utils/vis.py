# Written by Roy Tseng
#
# Based on:
# --------------------------------------------------------
# Copyright (c) 2017-present, Facebook, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################


from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import cv2
import numpy as np
import os
import pycocotools.mask as mask_util

from utils.coarse_mask_remap import mask_remap, mask_image_remap, box_image_remap
from utils.colormap import colormap
import utils.keypoints as keypoint_utils

# Use a non-interactive backend
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
import pdb
plt.rcParams['pdf.fonttype'] = 42  # For editing in Adobe Illustrator


_GRAY = (218, 227, 218)
_GREEN = (18, 127, 15)
_WHITE = (255, 255, 255)


def kp_connections(keypoints):
    kp_lines = [
        [keypoints.index('left_eye'), keypoints.index('right_eye')],
        [keypoints.index('left_eye'), keypoints.index('nose')],
        [keypoints.index('right_eye'), keypoints.index('nose')],
        [keypoints.index('right_eye'), keypoints.index('right_ear')],
        [keypoints.index('left_eye'), keypoints.index('left_ear')],
        [keypoints.index('right_shoulder'), keypoints.index('right_elbow')],
        [keypoints.index('right_elbow'), keypoints.index('right_wrist')],
        [keypoints.index('left_shoulder'), keypoints.index('left_elbow')],
        [keypoints.index('left_elbow'), keypoints.index('left_wrist')],
        [keypoints.index('right_hip'), keypoints.index('right_knee')],
        [keypoints.index('right_knee'), keypoints.index('right_ankle')],
        [keypoints.index('left_hip'), keypoints.index('left_knee')],
        [keypoints.index('left_knee'), keypoints.index('left_ankle')],
        [keypoints.index('right_shoulder'), keypoints.index('left_shoulder')],
        [keypoints.index('right_hip'), keypoints.index('left_hip')],
    ]
    return kp_lines


def convert_from_cls_format(cls_boxes, cls_segms,coarse_masks, cls_keyps):
    """Convert from the class boxes/segms/keyps format generated by the testing
    code.
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if coarse_masks is not None:
       segms_coarse = [b for b in coarse_masks if len(b) > 0]
       coarse_masks_all = np.concatenate(segms_coarse)
    else:
        coarse_masks_all = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, coarse_masks_all, keyps, classes


def vis_bbox_opencv(img, bbox, thick=1):
    """Visualizes a bounding box."""
    (x0, y0, w, h) = bbox
    x1, y1 = int(x0 + w), int(y0 + h)
    x0, y0 = int(x0), int(y0)
    cv2.rectangle(img, (x0, y0), (x1, y1), _GREEN, thickness=thick)
    return img


def get_class_string(class_index, score, dataset):
    class_text = dataset.classes[class_index] if dataset is not None else \
        'id{:d}'.format(class_index)
    return class_text + ' {:0.2f}'.format(score).lstrip('0')


def vis_one_image(
        fr,im, im_name, output_dir, boxes, segms=None, keypoints=None, thresh=0.9,
        kp_thresh=2, dpi=200, box_alpha=0.2, dataset=None, show_class=False,
        ext='pdf'):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(
            boxes, segms, keypoints)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return

    if segms is not None:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255

    dataset_keypoints, _ = keypoint_utils.get_keypoints()
    kp_lines = kp_connections(dataset_keypoints)
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]

    fig = plt.figure(frameon=False)
    fig.set_size_inches(im.shape[1] / dpi, im.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(im)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    mask_color_id = 0
    PAXdet = []
    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score < thresh:
            continue
        #save pax boxs
        w = bbox[2] - bbox[0] + 1
        h = bbox[3] - bbox[1] + 1
        w = np.maximum(w, 1)
        h = np.maximum(h, 1)
        if (classes[i] == 1):
            PAXdet.append([fr, i, bbox[0], bbox[1], w, h, score, classes[i]])
        print(dataset.classes[classes[i]], score)
        # show box (off by default, box_alpha=0.0)
        ax.add_patch(
            plt.Rectangle((bbox[0], bbox[1]),
                          bbox[2] - bbox[0],
                          bbox[3] - bbox[1],
                          fill=False, edgecolor='g',
                          linewidth=1, alpha=box_alpha))

        if show_class:
            ax.text(
                bbox[0]+(bbox[2] - bbox[0])/2.0, bbox[1]+(bbox[3] - bbox[1])/2.0,
                get_class_string(classes[i], score, dataset),
                fontsize=8,
                family='serif',
                bbox=dict(
                    facecolor='g', alpha=1, pad=0, edgecolor='none'),
                color='red')

        # show mask
        if segms is not None and len(segms) > i:
            img = np.ones(im.shape)
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1

            w_ratio = .4
            for c in range(3):
                color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio
            for c in range(3):
                img[:, :, c] = color_mask[c]
            e = masks[:, :, i]
            contour = cv2.findContours(
                e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[-2]
            #_, contour, hier = cv2.findContours(
                #e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

            for c in contour:
                polygon = Polygon(
                    c.reshape((-1, 2)),
                    fill=True, facecolor=color_mask,
                    edgecolor='w', linewidth=1.2,
                    alpha=0.6)
                ax.add_patch(polygon)

        # show keypoints
        if keypoints is not None and len(keypoints) > i:
            kps = keypoints[i]
            plt.autoscale(False)
            for l in range(len(kp_lines)):
                i1 = kp_lines[l][0]
                i2 = kp_lines[l][1]
                if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:
                    x = [kps[0, i1], kps[0, i2]]
                    y = [kps[1, i1], kps[1, i2]]
                    line = ax.plot(x, y)
                    plt.setp(line, color=colors[l], linewidth=1.0, alpha=0.7)
                if kps[2, i1] > kp_thresh:
                    ax.plot(
                        kps[0, i1], kps[1, i1], '.', color=colors[l],
                        markersize=3.0, alpha=0.7)
                if kps[2, i2] > kp_thresh:
                    ax.plot(
                        kps[0, i2], kps[1, i2], '.', color=colors[l],
                        markersize=3.0, alpha=0.7)

            # add mid shoulder / mid hip for better visualization
            mid_shoulder = (
                kps[:2, dataset_keypoints.index('right_shoulder')] +
                kps[:2, dataset_keypoints.index('left_shoulder')]) / 2.0
            sc_mid_shoulder = np.minimum(
                kps[2, dataset_keypoints.index('right_shoulder')],
                kps[2, dataset_keypoints.index('left_shoulder')])
            mid_hip = (
                kps[:2, dataset_keypoints.index('right_hip')] +
                kps[:2, dataset_keypoints.index('left_hip')]) / 2.0
            sc_mid_hip = np.minimum(
                kps[2, dataset_keypoints.index('right_hip')],
                kps[2, dataset_keypoints.index('left_hip')])
            if (sc_mid_shoulder > kp_thresh and
                    kps[2, dataset_keypoints.index('nose')] > kp_thresh):
                x = [mid_shoulder[0], kps[0, dataset_keypoints.index('nose')]]
                y = [mid_shoulder[1], kps[1, dataset_keypoints.index('nose')]]
                line = ax.plot(x, y)
                plt.setp(
                    line, color=colors[len(kp_lines)], linewidth=1.0, alpha=0.7)
            if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:
                x = [mid_shoulder[0], mid_hip[0]]
                y = [mid_shoulder[1], mid_hip[1]]
                line = ax.plot(x, y)
                plt.setp(
                    line, color=colors[len(kp_lines) + 1], linewidth=1.0,
                    alpha=0.7)

        output_name = os.path.basename(im_name) + '.' + ext
        #print(output_name)
        if fr%1==0:
            fig.savefig(os.path.join(output_dir, '{}'.format(output_name)), dpi=dpi)
            plt.close('all')
    return np.array(PAXdet)

def mask_box_remapping(img_rot, im, mask_image, coarse_mask,
                       score, classID, angle, objP, fr, save_mask=False):
    #pdb.set_trace()
    if save_mask:
        mask28_28 = mask_remap(coarse_mask, angle)
        assert mask28_28.shape == coarse_mask.shape, 'remapped person mask shape is different from predicted mask'
    else:
        mask28_28 = []
    # binary_mask = np.array(mask_image>0.5, dtype=np.uint8) # convert scoremap into binary mask
    # mask from segm_results
    mask_image[np.where(mask_image > 0)] = 255
    assert mask_image.shape==img_rot.shape[0:2]
    img_org = mask_image_remap(mask_image,im, angle)  # mask_image rescaled to original size
    #assert img_org.shape==im.shape[0:2], 'remapped mask image: {}, original image: {}'.format(img_org.shape, im.shape[0:2])
    # bbox feature
    [x, y, w, h] = cv2.boundingRect(img_org)
    # mask feature
    # centroids_cx,centroids_cy, contour_area, pixels_in_contour, arc_length = mask_features(img_org)
    PersonDet = [fr, objP, x, y, w, h, score, classID, angle]
    return PersonDet, mask28_28, img_org


def return_box_mask(img_rot, im, fr, angle, boxes, segms=None, segms_coarse=None,
                    thresh=0.5, save_coarse=False, bck_mask=False, class_list=None, feat_type='mask',
                    dataset=None, show_class=False, ext='pdf', verbose=False):

    """This function is mainly used for remapping detection boxes
    Remapped coarse and rotated masks are still unused
    """
    dets = []
    masks28 = []
    masksPB = []
    if class_list is None:
        class_list = [1, 2]
        
    if isinstance(boxes, list):
        boxes, segms, coarse_masks, keypoints, classes = convert_from_cls_format(
            boxes, segms, segms_coarse, None)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return dets, masks28, masksPB

    if segms is not None:
        masks = mask_util.decode(segms)

    # Display in largest to smallest order to reduce occlusion
    #areas_mask = [mask_util.area(m) for m in segms]
    #print(f'sorted mask areas: {sorted(areas_mask)}')
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    #print(f'sorted box areas: {sorted(areas)}')
    sorted_inds = np.argsort(-areas)
    #print('score_thr: {}, areas: {}'.format(thresh, areas))
    mask_color_id = 0
    objP=1
    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score <= thresh:
            continue
        w = bbox[2] - bbox[0] + 1
        h = bbox[3] - bbox[1] + 1
        w = np.maximum(w, 1)
        h = np.maximum(h, 1)
        # not necessary to use tis condition if model is finetuned dor PAX
        #area_mask = mask_util.area(segms[i])
        if classes[i] in class_list and areas[i]>10:
            # TODO: verify mask instance rotation is similar to the image rotation at full resolution
            img_mask = masks[:, :, i]
            #return rotated mask
            rle = mask_util.encode(np.asfortranarray(img_mask))
            masksPB.append(rle)
            if save_coarse:
                coarse28 =  coarse_masks[i,:,:]
            else:
                coarse28=None

            if angle!=0: #mask_image,coarse_mask,score, classID,angle,objP,fr
                box_remapd, coarse_remapd, img_mask = mask_box_remapping(img_rot,im,img_mask, coarse28,
                                                                        score, classes[i], angle, objP, fr,
                                                                         save_mask=save_coarse)
                # ToDo box image remap when we skip segmentation mask prediction
                # return remapped center instead of axis aligned bounding box
                if feat_type=='box':
                    x,y,w,h = box_image_remap(bbox, img_rot, im, angle)
                    box_remapd = [fr, objP, x, y, w, h, score, classes[i], angle]
            else:
                box_remapd = [fr, objP, bbox[0], bbox[1], w, h, score, classes[i], angle]
                coarse_remapd = coarse28
            objP+=1

            dets.append(box_remapd)
            if save_coarse:
                #for flower dataset return instance img_mask
                #return coarse_img_mask
                # 
                pos = np.array(box_remapd).astype('int')
                coarse_img_mask = np.zeros(img_mask.shape, dtype='float')
                try:
                    scaled_coarse = cv2.resize(coarse_remapd, (pos[4], pos[5]))
                    coarse_img_mask[ pos[3]:pos[3]+pos[5], pos[2]:pos[2]+pos[4]] = scaled_coarse
                except:
                    print('unable to resize coarse for (w, h): ({},{})'.format(pos[4], pos[5]))
                    coarse_img_mask = None
                #print(coarse_img_mask.max())
                assert coarse_img_mask is not None
                masks28.append(coarse_img_mask)
            if verbose:
                print(dataset.classes[classes[i]], score)

    return np.array(dets), np.array(masks28), masksPB

def return_box(img_rot, im, fr, angle, boxes, segms=None, segms_coarse=None,
                thresh=0.9, save_coarse=False, class_list=None, feat_type='box',
                dataset=None, show_class=False, ext='pdf'):

    dets = []
    if class_list is None:
        class_list = [1, 2]
    if isinstance(boxes, list):
        boxes, segms,coarse_masks, keypoints, classes = convert_from_cls_format(
            boxes, segms,segms_coarse, None)

    if boxes is None or boxes.shape[0] == 0:
        return dets

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    objP=1
    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        w = bbox[2] - bbox[0] + 1
        h = bbox[3] - bbox[1] + 1
        w = np.maximum(w, 1)
        h = np.maximum(h, 1)
        # not necessary to use tis condition if model is finetuned dor PAX
        if classes[i] in class_list:
            if angle!=0:
                if feat_type=='box':
                    x,y,w,h = box_image_remap(bbox, img_rot, im, angle)
                    box_remapd = [fr, objP, x, y, w, h, score, classes[i], angle]
            else:
                box_remapd = [fr, objP, bbox[0], bbox[1], w, h, score, classes[i], angle]
            objP+=1

            dets.append(box_remapd)
            print(dataset.classes[classes[i]], score)
    return np.array(dets)

def vis_clasp(
        fr,angle,im, im_name, output_dir, boxes, segms=None,segms_coarse=None, keypoints=None, thresh=0.9,
        kp_thresh=2, dpi=200, box_alpha=0.2, class_list=None, dataset=None, show_class=False,
        ext='pdf', show_mask=True):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms,coarse_masks, keypoints, classes = convert_from_cls_format(
            boxes, segms,segms_coarse, keypoints)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return

    if segms is not None:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255

    dataset_keypoints, _ = keypoint_utils.get_keypoints()
    kp_lines = kp_connections(dataset_keypoints)
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]

    fig = plt.figure(frameon=False)
    fig.set_size_inches(im.shape[1] / dpi, im.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(im)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    mask_color_id = 0
    for i in sorted_inds:
        if classes[i] in class_list:
            bbox = boxes[i, :4]
            score = boxes[i, -1]
            if score < thresh:
                continue
            #save pax boxs
            w = bbox[2] - bbox[0] + 1
            h = bbox[3] - bbox[1] + 1
            w = np.maximum(w, 1)
            h = np.maximum(h, 1)
            # show box (off by default, box_alpha=0.0)
            if classes[i] == 1:
                color_map = 'g'
            else:
                color_map = 'm'

            ax.add_patch(
                plt.Rectangle((bbox[0], bbox[1]),
                              bbox[2] - bbox[0],
                              bbox[3] - bbox[1],
                              fill=False, edgecolor=color_map,
                              linewidth=3, alpha=0.7))
            #bbox[0]+(bbox[2] - bbox[0])/2.0, bbox[1]+(bbox[3] - bbox[1])/2.0
            if show_class:
                #print(class_list)
                print(get_class_string(classes[i], score, dataset))
                ax.text(bbox[0], bbox[1],
                    get_class_string(classes[i], score, dataset),
                    fontsize=15,
                    family='serif',
                    bbox=dict(
                        facecolor='w', alpha=1, pad=0, edgecolor='none'),
                    color=color_map)
            # show mask
            if segms is not None and len(segms) > i and show_mask:
                img = np.ones(im.shape)
                color_mask = color_list[mask_color_id % len(color_list), 0:3]
                mask_color_id += 1

                w_ratio = .4
                for c in range(3):
                    color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio
                for c in range(3):
                    img[:, :, c] = color_mask[c]
                e = masks[:, :, i]
                contour = cv2.findContours(
                    e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[-2]
                #_, contour, hier = cv2.findContours(
                    #e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

                for c in contour:
                    polygon = Polygon(
                        c.reshape((-1, 2)),
                        fill=True, facecolor=color_map,
                        edgecolor='y', linewidth=2.5,
                        alpha=0.5)
                    ax.add_patch(polygon)

    #pdb.set_trace()
    fig.savefig(os.path.join(output_dir, '{}_{}'.format(angle, os.path.basename(im_name))), dpi=dpi)
    plt.close('all')

def vis_clasp_annos(
        fr,angle, ax, im_name, output_dir, boxes, segms=None,segms_coarse=None, keypoints=None, thresh=0.9,
        kp_thresh=2, dpi=200, box_alpha=0.2, class_list=None, dataset=None, show_class=False,
        ext='pdf', show_mask=True):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms,coarse_masks, keypoints, classes = convert_from_cls_format(
            boxes, segms,segms_coarse, keypoints)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return

    if segms is not None:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255

    dataset_keypoints, _ = keypoint_utils.get_keypoints()
    kp_lines = kp_connections(dataset_keypoints)
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    mask_color_id = 0
    for i in sorted_inds:
        if classes[i] in class_list:
            bbox = boxes[i, :4]
            score = boxes[i, -1]
            if score < thresh:
                continue
            #save pax boxs
            w = bbox[2] - bbox[0] + 1
            h = bbox[3] - bbox[1] + 1
            w = np.maximum(w, 1)
            h = np.maximum(h, 1)
            # show box (off by default, box_alpha=0.0)
            if classes[i] == 1:
                color_map = 'g'
            else:
                color_map = 'm'
            ax.add_patch(
                plt.Rectangle((bbox[0], bbox[1]),
                              bbox[2] - bbox[0],
                              bbox[3] - bbox[1],
                              fill=False, edgecolor=color_map,
                              linewidth=3, alpha=0.7))

            if show_class:
                ax.text(
                    bbox[0], bbox[1],
                    get_class_string(classes[i], score, dataset),
                    fontsize=15,
                    family='serif',
                    bbox=dict(
                        facecolor='w', alpha=1, pad=0, edgecolor='none'),
                    color=color_map)
            # show mask
            if segms is not None and len(segms) > i and show_mask:
                color_mask = color_list[mask_color_id % len(color_list), 0:3]
                mask_color_id += 1

                w_ratio = .4
                for c in range(3):
                    color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio

                e = masks[:, :, i]
                contour = cv2.findContours(
                    e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[-2]
                #_, contour, hier = cv2.findContours(
                    #e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

                for c in contour:
                    polygon = Polygon(
                        c.reshape((-1, 2)),
                        fill=True, facecolor=color_map,
                        edgecolor='y', linewidth=2.5,
                        alpha=0.5)
                    ax.add_patch(polygon)
    return ax


