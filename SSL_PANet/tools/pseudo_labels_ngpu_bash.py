#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed January 7 2022

@author: Abubakar Siddique
"""

from __future__ import division
from __future__ import print_function

import argparse
import distutils.util
import os
import sys
import pprint
import subprocess
from collections import defaultdict
from traceback import print_tb
from six.moves import xrange

# Use a non-interactive backend
#import matplotlib
#matplotlib.use('Agg')

import numpy as np
import cv2
import time
import torch
import imutils
import pycocotools.mask as mask_util
from skimage import measure
import imageio
import glob
#import imgaug.augmenters as iaa # TODO: to extract polygon section from image: train DAHE appearance model??
#import imgaug as ia
import torch.nn as nn
from torch.autograd import Variable
import _init_paths
import nn as mynn
from core.config import cfg, cfg_from_file, cfg_from_list, assert_and_infer_cfg
from core.test import im_detect_all, im_detect_regress, regressed_box2mask
from modeling.model_builder import Generalized_RCNN
import datasets.dummy_datasets as datasets
import utils.misc as misc_utils
import utils.net as net_utils
import utils.vis as vis_utils
from utils.process_box_mask import get_box_mask, get_box_mask_single_cat
from utils.detectron_weight_helper import load_detectron_weight
from utils.timer import Timer
from clasp2coco import define_dataset_dictionary_mp, Write_To_Json, Proxy2RealObj, \
    Write_ImagesInfo, Write_AnnotationInfo, load_clasp_json, get_frame_anns
from get_cluster_mode import Cluster_Mode
import random
import copy
import pandas as pd
import matplotlib.pyplot as plt
import pdb
import multiprocessing as mp
from itertools import islice
from init_pseudo_labels_dirs import get_all_dirs
from pycocotools.coco import COCO

class Pseudo_Labels(object):
    # goal is to reduce pseudo-labels computation time by the number of subprocess
    def __init__(self, gpu_id, init_params,  img_subset, ann_ids, 
                frame_ids, dataset_clasp, p_id=None, verbose=True):
        self.gpu_id = gpu_id
        self.p_id = p_id
        self.data = init_params['data']
        self.init_params = init_params
        self.load_ckpt_frcnn = None
        self.maskRCNN = None
        self.img_subset = img_subset
        self.verbose = verbose
        self.database = init_params['database']
        self.vis_annos = None
        self.vis_dir = None
        self.result_path = init_params['output_dir']
        self.det_thr = self.init_params['det_thr']
        self.nms_thr = self.init_params['nms_thr']
        self.regress_pred_score = init_params['regress_pred_score']
        self.class_list = self.init_params['class_list']
        self.angleSet = self.init_params['angleSet']
        self.all_scores = self.init_params['all_scores']
        self.regress_cluster = self.init_params['regress_aug_prop']
        self.save_dets_dict = {}
        self.save_dets_dict['dets_aug'] = open(
            os.path.join(self.result_path, '{}'.format('all_cam' + '_pb_1aug1nms.txt')), mode='w')

        self.detPB = []
        self.vis_path = os.path.join(self.result_path, 'vis')
        if not os.path.exists(self.vis_path):
            os.makedirs(self.vis_path)

        self.cluster_score_thr = self.init_params['cluster_score_thr']
        self.semi_supervised = self.init_params['semi_supervised']
        self.apply_cluster_mode = self.init_params['apply_cluster_mode']
        self.labeled_max_fr = init_params['labeled_max_fr']
        self.ranges = init_params['angle_ranges']


        #global variable
        #self.ann_id_count = ann_ids
        self.ann_ids = ann_ids
        #self.ann_id_count.append(1)
        self.semi_frames = init_params['semi_frames']
        self.dataset_clasp = dataset_clasp
        self.frame_ids = frame_ids
        self.labeled_frames = init_params['labeled_frames']



    @staticmethod
    def convert_from_cls_format(cls_boxes, cls_segms=None, coarse_masks=None, cls_keyps=None):
        """Convert from the class boxes/segms/keyps format generated by the testing
        code.
        """
        box_list = [b for b in cls_boxes if len(b) > 0]
        if len(box_list) > 0:
            boxes = np.concatenate(box_list)
        else:
            boxes = None
        if cls_segms is not None:
            segms = [s for slist in cls_segms for s in slist]
        else:
            segms = None
        if cls_segms is not None:
            segms_coarse = [b for b in coarse_masks if len(b) > 0]
            coarse_masks_all = np.concatenate(segms_coarse)
        else:
            coarse_masks_all = None
        if cls_keyps is not None:
            keyps = [k for klist in cls_keyps for k in klist]
        else:
            keyps = None
        classes = []
        for j in range(len(cls_boxes)):
            classes += [j] * len(cls_boxes[j])
        return boxes, segms, coarse_masks_all, keyps, classes

    @staticmethod
    def format_dets(cls_boxes, fr=None, dataset=None, class_list=None, thresh=0, class_id=None, angle=None):

        if isinstance(cls_boxes, list):
            # boxes, _,_, _, classes = convert_from_cls_format(cls_boxes)
            boxes = cls_boxes[class_id]
            classes = [class_id] * len(boxes)

        if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
            return

        # Display in largest to smallest order to reduce occlusion
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        sorted_inds = np.argsort(-areas)

        dets = []
        objP = 1
        for i in sorted_inds:
            bbox = boxes[i, :4]
            score = boxes[i, -1]
            w = bbox[2] - bbox[0] + 1
            h = bbox[3] - bbox[1] + 1
            w = np.maximum(w, 1)
            h = np.maximum(h, 1)
            # not necessary to use tis condition if model is finetuned dor PAX
            if classes[i] in class_list:
                box_remapd = [fr, objP, bbox[0], bbox[1], w, h, score, classes[i], angle]
                objP += 1

                dets.append(box_remapd)
                # print(dataset.classes[classes[i]], score)

        return np.array(dets)

    @staticmethod
    def gtbox2modes(anns_fr, fr_num, angle=0):
        fr_det = []
        for i, ann in enumerate(anns_fr):
            box = ann['bbox']
            score = 1
            catId = ann['category_id']
            fr_det.append([fr_num, i, box[0], box[1], box[2], box[3], score, catId, angle])
        return np.array(fr_det)

    @staticmethod
    def get_random_angles(ranges=None, factor=None):
        angleSet = [0]
        for intvl in ranges:
            angleSet += random.sample(range(intvl[0], intvl[1]), factor)
        return angleSet

    @staticmethod
    def rotated_boxes(masks, img_rot=None, angle=None):
        # rle to binary mask
        # rotated boxes are axis aligned
        rot_boxes = []
        for mask in masks:
            mask_org = mask_util.decode(mask)
            # binary_mask = np.array(mask_image>0.5, dtype=np.uint8) # convert scoremap into binary mask
            # mask from segm_results
            mask_org[np.where(mask_org > 0)] = 255

            mask_rot = imutils.rotate_bound(mask_org, angle)  # mask_image scaled to rotated image size
            assert mask_rot.shape == img_rot.shape[0:2]
            # assert img_org.shape==im.shape[0:2], 'remapped mask image: {}, original image: {}'.format(img_org.shape, im.shape[0:2])
            rot_boxes.append(np.array(cv2.boundingRect(mask_rot)))
        return np.array(rot_boxes)

    @staticmethod
    def get_masks(maskRCNN, detPB, im=None, vis_img=None, im_name=None, fr=None, pred_score=None, dataset=None,
                  class_list=None, timers=None, vis_dir=None, vis=False, img_fmt='jpg', angle=None,
                  class_id=None, apply_rgr=False):
        if apply_rgr:
            return_coarse = True
        else:
            return_coarse = False
        # use this function only to refine the detections to use as annos for a single class
        # TODO: How to format proposals variable for multi-claass??
        # TODO: get coarse masks to apply RGR
        dets_proposals = copy.deepcopy(detPB[:, 2:6])
        dets_proposals[:, 2:4] = dets_proposals[:, 0:2] + dets_proposals[:, 2:4]
        cls_boxes, cls_segms, clas_segms_coarse = regressed_box2mask(maskRCNN, im,
                                                  box_proposals=dets_proposals,
                                                  timers=timers,
                                                  test_aug=0,
                                                  soft_nms=0,
                                                  score_thr=0,
                                                  return_coarse=return_coarse)
        det_size = sum(len(cls_boxes[cl]) for cl in class_list)
        #print(f'angle: {angle} cls_boxes[class_id]: {cls_boxes[class_id]} \ndetPB: {detPB[:, 2:6]}')
        #TODO: verify that cls_boxes and detPB maintain index order
        assert len(cls_boxes[class_id]) == len(detPB)
        # assert len(class_list)==1, 'regression for augmented dets only workd for single class model.. mulit-class: full input proposals are used for all classes'
        assert det_size // len(class_list) == dets_proposals.shape[0], 'proposals size {}, prediction size {}'.format(
            det_size, dets_proposals)
        if fr % 1 == 0 and vis and det_size > 0:
            vis_img = vis_utils.vis_clasp_annos(
                fr,
                angle,
                vis_img,  # BGR -> RGB for visualization
                im_name,
                vis_dir,
                cls_boxes,
                segms=cls_segms,
                dataset=dataset,
                class_list=[class_id],
                box_alpha=1,
                show_class=True,
                thresh=pred_score,
                kp_thresh=2,
                ext=img_fmt,
                show_mask=1
            )

        if det_size > 0:
            # cls_boxes contain box proposals predictions for all the target classes
            # are they maintain index order of the proposals?
            det_class, mask_class = get_box_mask_single_cat(fr, cls_boxes, cls_segms, proposals=detPB, thresh=0,
                                                 angle=angle, class_id=class_id, dataset=dataset, 
                                                 cls_segms_coarse=clas_segms_coarse, img=im, rgr_refine=apply_rgr)
        else:
            mask_class = []
            det_class = []
        det_class = np.array(det_class)
        #print(f'cls_boxes[class_id]: {det_class[:,2:6]} \ndetPB: {detPB[:, 2:6]}')
        #for clasp it should works fine
        assert len(det_class) == len(mask_class) == len(detPB), f'{len(det_class)}=={len(mask_class)}=={len(detPB)}, {cls_boxes[class_id]}, {cls_segms[class_id]}'
        return det_class, mask_class, vis_img

    @staticmethod
    def init_fig(im):
        im = im[:, :, ::-1]
        fig = plt.figure(frameon=False)
        fig.set_size_inches(im.shape[1] / 200, im.shape[0] / 200)
        ax = plt.Axes(fig, [0., 0., 1., 1.])
        ax.axis('off')
        fig.add_axes(ax)
        ax.imshow(im)
        return ax, fig

    @staticmethod
    def get_gt_labels(fr, anns_fr, coco_json=None, angle=None):
        """segms are Polygon format in anns_fr
        fr_mask will be returned in rle format
        """
        fr_det = []
        fr_mask = []
        assert coco_json is not None
        #print(f'total flower found in GT {len(anns_fr)}')
        #print(f'labeled frame: {fr} angle: {angle}')
        for i, ann in enumerate(anns_fr):
            if angle>0:
                try:
                    label_mask = coco_json.annToMask(ann)
                except:
                    print(ann)
                    continue
                label_mask_rot = imutils.rotate_bound(label_mask, angle)
                label_mask_rot[label_mask_rot>0] = 255
                rle = mask_util.encode(np.asfortranarray(label_mask_rot))
                fr_mask.append(rle)
                #print(f'{i}: Bounding box = {mask_util.toBbox(rle)}')
                x,y,w,h = mask_util.toBbox(rle)
                fr_det.append([fr, i, x, y, w, h, 1.,1, angle])
            else:
                #print(ann)
                try:
                    rle = coco_json.annToRLE(ann)
                except:
                    print(ann)
                    continue
                fr_mask.append(rle)
                x,y,w,h = mask_util.toBbox(rle)
                fr_det.append([fr, i, x, y, w, h, 1.,1, angle])
        #assert len(fr_det)==len(fr_mask)>0
        return fr_det, fr_mask
    
    @staticmethod
    def vis_gt(im, boxs, gt_vis_path=None, imname=None):
        for bb in boxs:
            im = cv2.rectangle(im, (np.int(bb[2]), np.int(bb[3])), (np.int(bb[2]+bb[4]), np.int(bb[3]+bb[5])), (0,255,0), 4)
        # cv2.putText(imgcv, classGT, (int(xmin+w/2), int(ymin+h/2)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)
        cv2.imwrite(os.path.join(gt_vis_path, os.path.basename(imname)), im)
    
    def init_detector(self):
        # configure detector
        if not torch.cuda.is_available():
            sys.exit("Need a CUDA device to run the code.")
        torch.cuda.set_device(self.gpu_id)
        print(self.gpu_id)
        torch.set_num_threads(1)
        # args = parse_args()
        print('Called with args:')
        # print(args)

        if self.data == 'coco':
            self.dataset = datasets.get_coco_dataset()
            cfg.MODEL.NUM_CLASSES = len(self.dataset.classes)
        elif self.data == 'clasp2020':
            self.dataset = datasets.get_clasp_dataset()
            cfg.MODEL.NUM_CLASSES = len(self.dataset.classes)
        elif self.data == 'clasp1_2021':
            self.dataset = datasets.get_clasp1_dataset()
            cfg.MODEL.NUM_CLASSES = len(self.dataset.classes)
        elif self.data == 'clasp2_2021':
            self.dataset = datasets.get_clasp1_dataset()
            cfg.MODEL.NUM_CLASSES = len(self.dataset.classes)
        elif self.data == 'flower_2021':
            self.dataset = datasets.get_AppleA_dataset()
            cfg.MODEL.NUM_CLASSES = len(self.dataset.classes)
        elif self.data == "keypoints_coco":
            self.dataset = datasets.get_coco_dataset()
            cfg.MODEL.NUM_CLASSES = 2
        else:
            raise ValueError('Unexpected dataset name: {}'.format(self.data))

        print('load cfg from file: {}'.format(self.init_params['cfg_file']))
        cfg_from_file(self.init_params['cfg_file'])

        # set NMS
        cfg['TEST']['NMS'] = self.init_params['nms_thr']
        cfg['TEST']['SCORE_THRESH'] = self.init_params['det_thr']
        cfg.MODEL.LOAD_IMAGENET_PRETRAINED_WEIGHTS = False  # Don't need to load imagenet pretrained weights
        assert_and_infer_cfg()
        self.maskRCNN = Generalized_RCNN()
        self.maskRCNN.cuda()

        print("loading checkpoint %s" % (self.init_params['model_path']))
        checkpoint = torch.load(self.init_params['model_path'], map_location=lambda storage, loc: storage)
        if self.load_ckpt_frcnn:
            checkpoint_frcnn = torch.load(self.load_ckpt_frcnn, map_location=lambda storage, loc: storage)
            checkpoint_frcnn = checkpoint_frcnn['model']
        else:
            checkpoint_frcnn = None

        net_utils.load_ckpt(self.maskRCNN, checkpoint['model'], ckpt_frcnn=checkpoint_frcnn,
                            isTrain=False, FreezeResnetConv=False)

        self.maskRCNN = mynn.DataParallel(self.maskRCNN, cpu_keywords=['im_info', 'roidb'],
                                     minibatch=True, device_ids=[self.gpu_id])  # only support single GPU
        self.maskRCNN.eval()

    def regress_dets(self, proposals=None, fr=None, pred_score=None, isNMS=0, class_id=None):
        # no filtering during regression
        # How to format proposals variable for multi-claass: currently single class
        dets_proposals = copy.deepcopy(proposals[:, 2:6])
        dets_proposals[:, 2:4] = dets_proposals[:, 0:2] + dets_proposals[:, 2:4]
        # TODO: apply det_thr on the regressed augmented detections to reduce noises
        # TODO: for iter0, the single class det_proposals are used in 81 class predictor where input frame is unrotated version
        # !!!! For iter0, the augmented proposals may not be classified correctly among 81 classes
        # !!!! Avoid regression for iter0 to skip the wrong classification issue
        # !!!! solve the impact of unoriented frame uncertainty on the augmented proposals:
        # <<<<do not update the prediction score of the augmented proposals after regression>>>>
        cls_boxes = im_detect_regress(self.maskRCNN, self.rot_imgs_dict[0],
                                      box_proposals=dets_proposals,
                                      timers=self.timers,
                                      test_aug=0,
                                      soft_nms=isNMS,
                                      nms_thr=self.nms_thr,
                                      score_thr=0)

        # TODO: proposals might be classified as a wrong class: augmented bag proposals are regressed as person class (currently ignored)
        det_size = len(cls_boxes[class_id])
        # assert len(class_list)==1, 'regression for augmented dets only workd for single class model.. mulit-class: full input proposals are used for all classes'
        assert det_size==dets_proposals.shape[0], 'proposals size {}, prediction size {}'.format(det_size, dets_proposals.shape[0])

        if det_size > 0:
            dets = self.format_dets(cls_boxes, fr=fr, dataset=self.dataset, class_list=self.class_list,
                               thresh=0, class_id=class_id, angle=0)
            det_class = np.array(dets)
        else:
            det_class = np.empty(0)
        assert len(det_class)==len(proposals)
        return det_class

    def get_augmented_proposals(self, fr_num):
        #get the subset of frames for a specific proces
        if fr_num not in self.semi_frames and self.init_params['database']=='flower':
            #read unlabeled images for flower
            self.im_name = os.path.join(self.init_params['unlabeled_img_dir'], '{:08d}.png'.format(fr_num))
            assert os.path.exists(self.im_name), f'{self.im_name} is not exist for {self.dataset}'
        else:
            #read labeled images: 1 to gt_fr_max
            if self.init_params['database']=='flower':
                self.im_name = os.path.join(self.init_params['train_img_dir'], '{:09d}.png'.format(fr_num))
            else:
                #for clasp we are using unlabeled frames from training set
                self.im_name = os.path.join(self.init_params['train_img_dir'], '{:08d}.png'.format(fr_num))

            assert os.path.exists(self.im_name), f'{self.im_name} is not exist for {self.database}'

        if self.init_params['database']=='flower':
            #for flower dataset select random orientations for each frames
            self.angleSet = self.get_random_angles(ranges=self.ranges, factor=2)
            
        im = cv2.imread(self.im_name)

        self.rot_imgs_dict = {}
        self.detPB = []
        self.maskPB_rot = []
        self.detPB_rot = []
        masks_0 = None
        #print(f'angle set for test-time augmentation: {self.angleSet}')
        for angle in random.sample(self.angleSet, len(self.angleSet)):
            if angle > 0:
                if self.verbose:
                    cam = self.im_name.split('/')[-3]
                    #print(f'Image: {os.path.basename(self.im_name)}, Cam: {cam}, Rotated by: {angle}')
                                                                       
                imgrot = imutils.rotate_bound(im, angle)
            else:
                imgrot = im

            self.rot_imgs_dict[angle] = copy.deepcopy(imgrot)

            if fr_num not in self.semi_frames:
                # for 100% gt, self.semi_frames==all_frames
                #pseudo label generation for unlabeled frames
                cls_boxes, cls_segms, cls_keyps, \
                cls_segms_coarse = im_detect_all(self.maskRCNN, imgrot,
                                                timers=self.timers,
                                                test_aug=False,
                                                soft_nms=True,
                                                nms_thr=self.nms_thr,
                                                score_thr=self.det_thr,
                                                return_coarse=True
                                                )

                if cls_boxes is not None:
                    dets_rot, masks_rot = get_box_mask(fr_num, cls_boxes, cls_segms,
                                                       cls_keyps, thresh=self.det_thr,
                                                       angle=angle, class_list=self.class_list,
                                                       dataset=self.dataset, verbose=self.verbose)
                    # get remapped dets and maintain the index of dets_rot
                    dets, _, _ = vis_utils.return_box_mask(
                        imgrot[:, :, ::-1],
                        im[:, :, ::-1],
                        fr_num,
                        angle,
                        cls_boxes,
                        cls_segms,
                        cls_segms_coarse,
                        dataset=self.dataset,
                        class_list=self.class_list,
                        save_coarse=False,
                        thresh=self.det_thr,
                        verbose=self.verbose
                    )
                    assert len(dets) == len(masks_rot) == len(dets_rot), \
                        'found #remap dets: {}, #masks_rot: {}, #dets_rot: {}'.format(
                            len(dets), len(masks_rot), len(dets_rot))

                    # collect augmented dets to apply MI-MS
                    if (len(dets) > 0):
                        for i, box in enumerate(dets):
                            # append detections for each orientation
                            if self.init_params['database'] in ['clasp1', 'clasp2', 'flower']:
                                if (box[6] >= 0.7 and box[7] == 1) or (box[6] >= 0.5 and box[7] != 1):
                                    # if self.im_name.split('/')[-3] in ['E_9']:
                                    #     if box[2]+box[4]/2 < 1350:
                                    #         self.detPB.append(box)
                                    #         self.maskPB_rot.append(masks_rot[i])
                                    #         self.detPB_rot.append(dets_rot[i])
                                    # else:
                                    self.detPB.append(box)
                                    self.maskPB_rot.append(masks_rot[i])
                                    self.detPB_rot.append(dets_rot[i])

                            self.all_scores['dets']['det_score'].append(box[6])
                            self.all_scores['dets']['class_id'].append(box[7])
                            self.all_scores['dets']['frame'].append(fr_num)

        #print(f'augmented proposals size {len(self.detPB)}')
        self.detPB = np.array(self.detPB)
        self.detPB_rot = np.array(self.detPB_rot)
        assert len(self.detPB) == len(self.detPB_rot)

    def regress_proposals(self, fr_num):
        # no filtering during regression
        # save_coarse_mask_PANet(PAXdet,PAXmask,out_path)
        # regress bbox to reduce localization noise in the remapped detections
        #TODO: apply regress only when the number of class<=2
        if self.regress_cluster:
            # apply regression on the augmented set separately for each class
            det_cl = {}
            for cl in self.class_list:
                det_cl[cl] = self.detPB[self.detPB[:, 7] == cl]
                det_befr_reg = copy.deepcopy(det_cl[cl])
                # regress to reduce noise in remap
                if len(det_cl[cl]) > 0:
                    class_dets = self.regress_dets(proposals=det_cl[cl], fr=fr_num,
                                              pred_score=0, isNMS=0, class_id=cl)
                    det_cl[cl] = class_dets
                    #self.detPB[self.detPB[:, 7] == cl][:, 2:6] = class_dets[:,2:6]
                    # !!! is the regressed dets maintain class specific cardinality??
                    assert len(det_befr_reg)==len(det_cl[cl]),\
                        'proposals size {} prediction size {}'.format(len(det_befr_reg), len(det_cl[cl]))
            # detPB will be updated using regressed dets whatever the objectness score: no filtering using det_thr or nms
            #TODO: combine rotational invariance and instance uncertainty
            #TODO: detPB[:, 7] = detPB[:, 7]*regressed_dets[:, 7]
            #print('det_cl: {}'.format(det_cl))
            box_list = [b for _, b in det_cl.items() if len(b) > 0]

            if len(box_list) > 0:
                regressed_dets = np.concatenate(box_list)
                assert len(self.detPB) == len(regressed_dets)
                # <<<<do not update the prediction score of the augmented proposals after regression>>>>
                self.detPB = regressed_dets
            else:
                self.detPB = []

    def predict_modes(self, fr_num):
        # call cluster selection method on the regressed test-time augmented predictions
        if fr_num % 2 == 0:
            show_result = True
        else:
            show_result = False
        MI_MS = Cluster_Mode(self.detPB, fr_num, self.angleSet, copy.deepcopy(self.rot_imgs_dict[0]),
                             self.vis_path, self.save_dets_dict, vis=show_result,
                             save_modes=True, cluster_scores_thr=self.cluster_score_thr,
                             nms=1, save_scores=self.init_params['all_scores'], global_frame=fr_num,
                             bw_type='estimated', im_name=self.im_name, verbose=self.verbose)
        det_indexs, self.init_params['all_scores'], cluster_modes = MI_MS.get_modes()

        return cluster_modes, det_indexs
    
    def get_annos_cluster_mode(self, cluster_modes, masks_0=None, fr_num=None,
                               imgrot=None, angle=None, pred_score=0, verbose=False):
        # cluster_modes: bbox of all categories from an image
        if self.vis_annos:
            imgrot_vis, fig = self.init_fig(copy.deepcopy(imgrot))
        else:
            imgrot_vis = fig = None

        if angle == 0:
            det_cl = {}
            mask_cl = {}
            for cl in self.class_list:
                det_cl[cl] = cluster_modes[cluster_modes[:, 7] == cl]
                if len(det_cl[cl]) > 0:
                    det_cl[cl], mask_cl[cl], imgrot_vis = self.get_masks(self.maskRCNN, det_cl[cl], im=imgrot,
                                                                    vis_img=imgrot_vis, im_name=os.path.basename(self.im_name),
                                                                    fr=fr_num, pred_score=0, dataset=self.dataset,
                                                                    class_list=self.class_list, vis_dir=self.vis_dir,
                                                                    vis=self.vis_annos, img_fmt='jpg',
                                                                    angle=angle, class_id=cl, apply_rgr=self.init_params['apply_RGR'])
            box_list = [b for _, b in det_cl.items() if len(b) > 0]
            mask_list = [m for _, m in mask_cl.items() if len(m) > 0]
            if len(box_list) > 0:
                fr_det = np.concatenate(box_list)
                fr_mask = np.concatenate(mask_list)
            else:
                # return empty pseudo labels
                fr_det = fr_mask = cluster_modes = []

                if self.vis_annos:
                    fig.savefig(os.path.join(self.vis_dir, '{}_{}'.format(angle, os.path.basename(self.im_name))), dpi=200)
                    plt.close('all')
            # try:
            #     assert len(fr_det) == len(fr_mask) == len(cluster_modes), f'{len(fr_det)}=={len(fr_mask)}=={len(cluster_modes)}'
            # except:
            #     print(f'regression discard {len(cluster_modes)-len(fr_det)} anns')
            assert len(fr_det) == len(fr_mask) == len(cluster_modes), f'{len(fr_det)}=={len(fr_mask)}=={len(cluster_modes)}'

            masks_0 = copy.deepcopy(fr_mask)
            self.updated_cluster_mode = copy.deepcopy(fr_det)

            # print('collect training examples: frame: {}, #detection: {}, angle: {}'.format(fr,
            # len(fr_det),
            # angle))
        else:
            # use masks to remap cluster modes from theta=0 to theta= 6, 84, 90 ,....
            assert masks_0 is not None
            rotated_modes = self.rotated_boxes(masks_0, img_rot=imgrot, angle=angle)
            #initial SSL model might fail to generate masks for some anns boxs
            # fr_det at theta=0 should be the cluster modes
            # self.updated_cluster_mode and masks_0 or rotated_modes maintain class and box orders
            self.updated_cluster_mode[:, 2:6] = rotated_modes

            det_cl = {}
            mask_cl = {}
            for cl in self.class_list:
                det_cl[cl] = self.updated_cluster_mode[self.updated_cluster_mode[:, 7] == cl]
                if len(det_cl[cl]) > 0:
                    det_cl[cl], mask_cl[cl], imgrot_vis = self.get_masks(self.maskRCNN, det_cl[cl], im=imgrot,
                                                                    vis_img=imgrot_vis, im_name=os.path.basename(self.im_name),
                                                                    fr=fr_num, pred_score=pred_score, dataset=self.dataset,
                                                                    class_list=self.class_list, vis_dir=self.vis_dir,
                                                                    vis=self.vis_annos, img_fmt='jpg',
                                                                    angle=angle, class_id=cl, apply_rgr=self.init_params['apply_RGR'])
            box_list = [b for _, b in det_cl.items() if len(b) > 0]
            mask_list = [m for _, m in mask_cl.items() if len(m) > 0]
            if len(box_list) > 0:
                fr_det = np.concatenate(box_list)
                fr_mask = np.concatenate(mask_list)
            else:
                # return empty pseudo labels
                fr_det = fr_mask = cluster_modes = []

                if self.vis_annos:
                    fig.savefig(os.path.join(self.vis_dir, '{}_{}'.format(angle, os.path.basename(self.im_name))), dpi=200)
                    plt.close('all')

            # try:
            #     assert len(fr_det) == len(fr_mask) == len(
            #         cluster_modes), f'{len(fr_det)}=={len(fr_mask)}=={len(cluster_modes)}'
            # except:
            #     print(f'regression discard {len(cluster_modes) - len(fr_det)} anns')
            assert len(fr_det) == len(fr_mask) == len(cluster_modes), f'{len(fr_det)}=={len(fr_mask)}=={len(cluster_modes)}'

            if verbose:
                print(f'collect training examples: frame: {fr_num}, \
                #detection: {len(fr_det)}, angle: {angle}')
        return fr_det, fr_mask, masks_0

    def pseudo_labels_selection(self, fr_num, cluster_modes, det_indexs):
        #here det_indexs will be the position of the selected clusters dets in detPB
        masks_0 = None
        if not self.apply_cluster_mode:
            detf = self.detPB_rot[det_indexs]
            maskf = [self.maskPB_rot[ind] for ind in det_indexs]
            assert len(detf) == len(maskf)

        if self.verbose:
            print('Frame: {}, #detection: {}'.format(fr_num, len(cluster_modes)))
        #start loop for all unique angles and save corresponding image and detections
        #[CXbox, CYbox, fr, detBox[1], x, y, w, h, score, classID, angle]
        # use percent GT json for semi-supervised
        if self.semi_supervised and fr_num in self.semi_frames:
            # update cluster modes: [0:fr, 1:ind, 2:x, 3:y, 4:w, 5:h, 6:score, 7:class, 8:angle] from box gt
            # and then apply augmentation
            # cluster_modes (only box) are replaced from the manual labels
            anns_fr = get_frame_anns(self.init_params['percent_clasp_gt'], fr_num)
            try:
                assert len(anns_fr) > 0
                #only box anns will used for clasp where mask label will be generated using regression
                if self.init_params['database'] in ['clasp1', 'clasp2']:
                    cluster_modes = self.gtbox2modes(anns_fr, fr_num, angle=0)
                else:
                    cluster_modes = []
            except:
                print(f'found labeled frame {fr_num} without anns')

        if len(cluster_modes)>0 or len(anns_fr) > 0:
            if self.init_params['database']=='flower':
                self.pseudo_labels_angles = [0] #random.sample(self.angleSet, len(self.angleSet)//2)
            else: 
                self.pseudo_labels_angles = [6, 90, 270, 354] #[6, 84, 90, 96, 174, 180, 186, 270, 354]
            self.pseudo_labels_angles = random.sample(self.pseudo_labels_angles, len(self.pseudo_labels_angles))

            # first angle should be zero
            if 0 not in self.pseudo_labels_angles:
                self.pseudo_labels_angles.insert(0, 0)
            else:
                self.pseudo_labels_angles.remove(0)
                self.pseudo_labels_angles.insert(0, 0)
            # theta=180 is will be used furing training
            if 180 in self.pseudo_labels_angles:
                self.pseudo_labels_angles.remove(180)
            #print(f'angle set for pseudo labels: {self.pseudo_labels_angles}')

            for theta in self.pseudo_labels_angles:
                imgrot = self.rot_imgs_dict[theta]
                #[!] GT labels are regressed to generate box to mask for clasp
                #[!] GT labels are not regressed since box to mask already available for flowers
                if self.init_params['database'] in ['clasp1', 'clasp2']:
                    #we need to apply regression for both labeled and unlabeled frames
                    fr_det,  fr_mask, masks_0 = self.get_annos_cluster_mode(cluster_modes,
                                                                            masks_0=masks_0, fr_num=fr_num,
                                                                            imgrot=imgrot, pred_score=0,
                                                                            angle=theta, verbose=self.verbose)
                    if self.verbose:
                        print(f'instance certainty score: {fr_det[:, 6]}, rotation invariant score: {cluster_modes[:, 6]}')
                    #instance uncertainties are replaced with rotation invariance
                    fr_det[:, 6] = cluster_modes[:, 6]

                # flower: apply regression only for pseudo labels only
                elif self.init_params['database'] in ['flower']:
                    if fr_num in self.semi_frames:
                        assert len(anns_fr)>0
                        #rotate anns: mask is in polygon format
                        # fr_boxs, fr_masks will be updated inplace for each orientation 
                        fr_det,fr_mask = self.get_gt_labels(fr_num, anns_fr, 
                                                        coco_json=self.init_params['percent_clasp_gt'], 
                                                        angle=theta)
                    else:
                        # TODO: apply RGR
                        assert len(cluster_modes)>0
                        fr_det,  fr_mask, masks_0 = self.get_annos_cluster_mode(cluster_modes,
                                                        masks_0=masks_0, fr_num=fr_num,
                                                        imgrot=imgrot, pred_score=0,
                                                        angle=theta, verbose=self.verbose)
                        if self.verbose:
                            print(f'instance certainty score: {fr_det[:, 6]}, rotation invariant score: {cluster_modes[:, 6]}')
                        #instance uncertainties are replaced with rotation invariance
                        try:
                            fr_det[:, 6] = cluster_modes[:, 6]
                        except:
                            print(f'regressed scores: {fr_det[:, 6]} are used as pseudo labels score')

                else:
                    print('{} is not available'.format(self.init_params['database']))
                    fr_det = []
                    fr_mask = []

                if len(fr_det)>0:
                    if self.verbose:
                        print(f'training examples: frame: {fr_num}, #detection: {len(fr_det)}, angle: {theta}')
                    #save image info
                    imgrot = self.rot_imgs_dict[theta]
                    imgIdnew = 10000 * int('%06d' % fr_num) + theta
                    self.frame_ids.append(imgIdnew) # populate frame ids to verify the process terminate
                    imgname = '{:08d}.png'.format(imgIdnew)
                    img_write_path = self.init_params['AugImgDir'] + '/' + imgname
                    if fr_num in self.semi_frames:
                       self.vis_gt(self.rot_imgs_dict[theta], fr_det, gt_vis_path=self.vis_path, imname=img_write_path)

                    if self.verbose:
                        print(f'Writing image {imgname}')
                    cv2.imwrite(img_write_path, imgrot)
                    self.dataset_clasp = Write_ImagesInfo(imgrot, imgname, int(imgIdnew), self.dataset_clasp)

                    # save anns
                    for ib,box in enumerate(fr_det):
                        # since only consider the cluster modes
                        if (box[6]>=self.cluster_score_thr[0] and box[7]==1) or \
                            (box[6]>=self.cluster_score_thr[1] and box[7]!=1):

                            bboxfinal = [round(x, 2) for x in box[2:6]]
                            mask = fr_mask[ib]
                            area = mask_util.area(mask)#polygon area
                            assert len(box)==9, 'box {}'.format(box)
                            #[fr, i, bbox[0], bbox[1], w, h, score, classes[i]]
                            if self.database in ['clasp1', 'clasp2']:
                                if box[7]==1:
                                    catID = 1
                                else:
                                    catID = 2
                            else:
                                catID = 1
                            #score: cluster_score or cluster_mode regressed score
                            score = box[6]
                            #1000 * int('%06d' % (fr_num+ib+1)) + theta 
                            annID = int(f'{ib+1}{fr_num}{self.p_id+theta}')# fr_num is unique in multiple precesses
                            self.ann_ids.append(annID)

                            segmPolys = []  # mask['counts'].decode("utf-8") #[]
                            bmask = mask_util.decode(mask)
                            contours = measure.find_contours(bmask, 0.5)
                            #contours = cv2.findContours(bmask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                            for contour in contours:
                                contour = np.flip(contour, axis=1)
                                segmentation = contour.ravel().tolist()
                                #print(f'segm poly size {len(segmentation)}')
                                if len(segmentation)>0:
                                    segmPolys.append(segmentation)
                            assert int(imgIdnew)== int(os.path.basename(img_write_path).split('.')[0])
                            #save annotation for for each image
                            if len(segmPolys)>0:
                                self.dataset_clasp = Write_AnnotationInfo(bboxfinal, segmPolys, int(imgIdnew),
                                                                    int(annID), catID, int(area), self.dataset_clasp,
                                                                            instance_certainty=score)

    def pseudo_labels_main(self):
        """
        Iterate over a video frames to collect the automatically generated pseudo labels
        """
        for fr_num in random.sample(self.img_subset, len(self.img_subset)):

            self.timers = defaultdict(Timer)
            start_time = time.time()

            self.get_augmented_proposals(fr_num)
            # regress proposals
            if len(self.detPB) > 0:
                self.regress_proposals(fr_num)
                try:
                    assert len(self.detPB) > 0
                    cluster_modes, det_indexs = self.predict_modes(fr_num)
                except:
                    det_indexs = cluster_modes = []
            else:
                det_indexs = cluster_modes = []

            if fr_num not in self.semi_frames:
                # use cluster modes to get pseudo-labels and
                # update coco data structure dict to populate the selected pseudo labels
                if len(cluster_modes) > 0:
                    self.pseudo_labels_selection(fr_num, cluster_modes, det_indexs)
                else:
                    print(f'no pseudo labels found at {fr_num}')
            else:
                self.pseudo_labels_selection(fr_num, cluster_modes, det_indexs)

            if fr_num in self.semi_frames:
                print(f"PID: {self.p_id}, Labeled Frame: {fr_num}, Execution time {time.time() - start_time} secs")
            else:
                print(f"PID: {self.p_id}, Unlabeled Frame: {fr_num}, Execution time {time.time() - start_time} secs")


def pseudo_main(q, init_params, i, process_frames,
                ann_ids, frame_ids, dataset_clasp):
    gpu_id = init_params['cuda_list'][i]
    init_params['process_id'] = i
    print(f'initiate process {i} using cuda {gpu_id} for total frames {len(process_frames)}')
    pseudo_labeler = Pseudo_Labels(gpu_id, init_params,  process_frames,
                                   ann_ids, frame_ids, dataset_clasp, 
                                   p_id=i,verbose=init_params['verbose'])
    pseudo_labeler.init_detector()
    pseudo_labeler.pseudo_labels_main()
    #, 'train_data':dataset_clasp, 'all_scores':all_scores
    print(f'PID: {i} finished assigned frames')
    q.put({'process_finished': True})

def split_frames(num_processes, all_frames):
    max_limit = len(all_frames)//num_processes
    assert max_limit!=1
    lengths_frame = [max_limit] * num_processes
    lengths_frame[-1] += abs(sum([max_limit] * num_processes) - len(all_frames))
    all_frames_iter = iter(all_frames)
    return [list(islice(all_frames_iter, elem)) for elem in lengths_frame]

def define_scores_dict_mp(manager):
    scores_dict = manager.dict()

    scores_dict['dets'] = manager.dict()
    scores_dict['dets']['det_score']= manager.list()
    scores_dict['dets']['class_id'] = manager.list()
    scores_dict['dets']['frame'] = manager.list()

    scores_dict['clusters'] = manager.dict()
    scores_dict['clusters']['cluster_score']= manager.list()
    scores_dict['clusters']['class_id'] = manager.list()
    scores_dict['clusters']['frame'] = manager.list()

    return scores_dict

def parse_args():
    """Parse input arguments"""
    parser = argparse.ArgumentParser(description='Train a X-RCNN network')

    parser.add_argument(
        '--database', dest='database', required=True,
        help='Database to use: clasp1 or clasp2', default='clasp2')

    parser.add_argument(
        '--cfg', dest='cfg', required=True,
        help='Config file for training (and optionally testing)')

    parser.add_argument(
        '--label_percent',
        help='percent of manual annotations used in semi-SL',
        default=1, type=int)

    parser.add_argument(
        '--ssl_iter',
        help='SSL iteration index to make sure the pretrained model is loaded properly',
        default=0, type=int)

    parser.add_argument('--model_type', type=str, default='segm')

    parser.add_argument(
        '--no_cuda', dest='cuda', help='Do not use CUDA device', action='store_false')

    # Optimization
    # These options has the highest prioity and can overwrite the values in config file
    # or values set by set_cfgs. `None` means do not overwrite.
    parser.add_argument(
        '--bs', dest='batch_size',
        help='Explicitly specify to overwrite the value comed from cfg_file.',
        type=int)
    parser.add_argument(
        '--nw', dest='num_workers',
        help='Explicitly specify to overwrite number of workers to load data. Defaults to 4',
        type=int)
    parser.add_argument(
        '--iter_size',
        help='Update once every iter_size steps, as in Caffe.',
        default=1, type=int)

    parser.add_argument(
        '--o', dest='optimizer', help='Training optimizer.',
        default=None)
    parser.add_argument(
        '--lr', help='Base learning rate.',
        default=None, type=float)
    parser.add_argument(
        '--lr_decay_gamma',
        help='Learning rate decay rate.',
        default=None, type=float)

    return parser.parse_args()

if __name__ == '__main__':
    """Script to generate N-fold pseudo-labels in SSL using multi-processing
    1. Rotation: 20 fold: fixed/randomly
    2. TODO: Color Jitter and Scale Jitter: 5x4 fold: randomly select color and scale for each
    3. TODO: Rotation, Color Jitter, and Scale Jitter: 4x3x2 fold: randomly select color and scale for each  
    """
    #torch.multiprocessing.set_start_method('spawn')
    import warnings
    warnings.filterwarnings("ignore")
    # For flower:
    # one iteration for pseudo labels generation takes 1 hr
    # 2 GPUs training for 20k iterations take 2 hr 35 minutes 
    args = parse_args()
    print('Called with args:')
    print(args)
    # start multiprocess for multi-camera pseudo label generation
    storage = '/media/siddique/464a1d5c-f3c4-46f5-9dbb-bf729e5df6d62'
    num_gpus = 2
    #storage = '/media/abubakarsiddique'
    # num_gpus = 4


    models_dir = 'PANet_Models'
    model_type = 'modified_loss' #'modified_loss_semi' #'modified_loss' 'modified_loss_wo_reg'
    exp = args.ssl_iter
    percent_gt = args.label_percent
    init_params = {}
    init_params['database'] = args.database
    init_params['data'] = f'{args.database}_2021'
    
    init_params['regress_aug_prop'] = True
    init_params['semi_supervised'] = True
    init_params['apply_cluster_mode'] = True
    init_params['verbose'] = False
    
    if args.database in ['clasp1', 'clasp2']:
        if num_gpus==2:
            init_params['cuda_list'] = [0,1,0,1,0,1]
        if num_gpus==3:
           init_params['cuda_list'] = [0,0,1,1,2,2,3,3]

        init_params['apply_RGR'] = False
        init_params['det_thr'] = 0.5
        init_params['class_list'] = [1,2]
        init_params['nms_thr'] = 0.5
        init_params['cluster_score_thr'] = [0.6, 0.2]
        init_params['regress_pred_score'] = 0.1 # currently not used

    elif args.database in ['flower']:
        init_params['apply_RGR'] = True
        # use 0.5++
        init_params['det_thr'] = 0.6
        init_params['cuda_list'] = [0,1,0,1]
        init_params['class_list'] = [1]
        init_params['nms_thr'] = 0.3
        #use 0.4-0.5 or nms to avoid noisy clustering
        init_params['cluster_score_thr'] = [0.4, 0.4]
        init_params['regress_pred_score'] = 0.2
        
    init_params['save_data'] = True
    #20 fold rotation: fixed
    init_params['angleSet'] = [0, 6, 12, 78, 84, 90, 96, 102, 168, 174,
                               180, 186, 192, 258, 264, 270, 276, 342, 348, 354]
    #20 fold rotation: randomly selected
    init_params['angle_ranges'] = [[1, 24], [78, 96], [168, 192], [258, 276], [342, 354]]

    init_params['cfg_file'] = args.cfg

    #get all required dirs
    init_params, all_frames = get_all_dirs(args, exp, init_params, storage, 
                                    models_dir, model_type, percent_gt=percent_gt)

    #https://pytorch.org/docs/stable/multiprocessing.html
    #torch.multiprocessing.set_start_method("spawn")
    mp.set_start_method('spawn')
    #mp.get_context("spawn")

    #define global variables
    #http://ld2012.scusa.lsu.edu/python/library/multiprocessing.html
    manager = mp.Manager()
    ann_ids = manager.list()
    frame_ids = manager.list()
    # initiate dataset_clasp dictionary using global mp dicts to update train data
    dataset_clasp = define_dataset_dictionary_mp(manager, database=args.database)
    print(dataset_clasp)
    #pdb.set_trace()
    # to compute the det score and cluster score threshold
    init_params['all_scores'] = define_scores_dict_mp(manager)
    #set of gpus
    num_gpus = torch.cuda.device_count()

    #split all_frames to all processes: nGPUS*3
    num_processes = len(init_params['cuda_list'])
    all_frames = random.sample(all_frames, len(all_frames))
    splitted_frames = split_frames(num_processes, all_frames)
    assert len(all_frames)==sum([len(set(grp)) for grp in splitted_frames])
    #pdb.set_trace()
    #list of processes
    q=list(range(num_processes))
    start_time = time.time()
    #assign process to each gpu
    p = {}
    for i in q:
        q[i] = mp.Queue()
        # Pass GPU number through q
        p[i] = mp.Process(target=pseudo_main,
                       args=(q[i], init_params, i, splitted_frames[i],
                             ann_ids, frame_ids, dataset_clasp)
                       )
        p[i].start()

    #main loop to save psudo labels JSON
    while True:
        check_terminate = [q[i].get()['process_finished'] for i in range(len(q))]
        if all(check_terminate):
            print('all queue status {}'.format(check_terminate))
            # image ids and the anns ids should be unique for training dataset
            assert len(frame_ids)==len(set(frame_ids))
            assert len(ann_ids) == len(set(ann_ids))

            if init_params['save_data']:
                dataset_clasp = Proxy2RealObj(dataset_clasp, database=args.database)
                Write_To_Json(init_params['dataJSON'], dataset_clasp)
                print(f"total time for {args.database}: {time.time() - start_time} sec")
                #TODO: test uniqueness of all annotation ids

                # Ctrl+/
                # Dframe_dets = pd.DataFrame(init_params['all_scores']['dets'])
                # Dframe_dets.to_csv(init_params['cluster_score_file'], mode='w', index=False)
                #
                # Dframe_clusters = pd.DataFrame(init_params['all_scores']['clusters'])
                # Dframe_clusters.to_csv(init_params['cluster_score_file'], mode='w', index=False)
            
            break
        else:
            continue
    #TODO: implement terminate rules for each sub-processes

    for i in list(range(num_processes)):
        p[i].join()
        p[i].terminate() 
